# Example env for ESPDragon CLI
# Replace values with your deployment's configuration

# Base public URL for your Ollama server (required for LLM)
OLLAMA_PUBLIC_URL="https://effective-parakeet-wr4w4j6pxxvvc9rvq-11434.app.github.dev"
# Model to use for the Ollama run (requested)
OLLAMA_MODEL="codegpt/replit-code-v1_5-3b"
OLLAMA_API_PATH="/api/generate"
# Optional API key for Ollama if required
# OLLAMA_API_KEY="..."

# Confirm scanning authorization via env (alternative to --confirm flag)
# WARNING: Setting this asserts you have explicit authorization to scan targets.
ESPDRAGON_AUTHORIZED="yes"

# Optional runtime tuning
# OLLAMA_TEMPERATURE="0.2"
# OLLAMA_MAX_TOKENS="512"